# This ebuild was auto-generated by homeassistant script, and the script was not able to find a better candidate.
EAPI=8

DISTUTILS_USE_PEP517=setuptools
PYTHON_COMPAT=( python3_{12,13{,t}} )
GENERATED_IUSE="auto-gptq autoawq bitsandbytes codecarbon deepspeed diffusers flash-attn ipex llama-cpp llm-swarm onnxruntime onnxruntime-gpu openvino peft py-txi quality sentence-transformers tensorrt-llm test timm torch-ort torchao vllm"
IUSE="${GENERATED_IUSE}"

PYPI_NO_NORMALIZE=1
inherit distutils-r1 pypi

DESCRIPTION=""
HOMEPAGE="
  https://pypi.org/project/optimum-benchmark/"

LICENSE=""
SLOT="0"
KEYWORDS="amd64 arm64"

REQUIRES_DIST="
	accelerate
	auto-gptq; extra == 'auto-gptq'
	autoawq; extra == 'autoawq'
	bitsandbytes; extra == 'bitsandbytes'
	codecarbon; extra == 'codecarbon'
	colorlog
	datasets
	deepspeed; extra == 'deepspeed'
	diffusers; extra == 'diffusers'
	flash-attn; extra == 'flash-attn'
	flatten-dict
	hydra-core
	hydra-joblib-launcher; extra == 'testing'
	llama-cpp-python; extra == 'llama-cpp'
	llm-swarm; extra == 'llm-swarm'
	nvidia-ml-py
	omegaconf
	onnxruntime-training; extra == 'torch-ort'
	optimum; extra == 'auto-gptq'
	optimum>=1.18.0; extra == 'torch-ort'
	optimum[ipex]>=1.18.0; extra == 'ipex'
	optimum[nncf,openvino]>=1.18.0; extra == 'openvino'
	optimum[nvidia]>=1.18.0; extra == 'tensorrt-llm'
	optimum[onnxruntime-gpu]>=1.18.0; extra == 'onnxruntime-gpu'
	optimum[onnxruntime]>=1.18.0; extra == 'onnxruntime'
	pandas
	peft; extra == 'peft'
	psutil
	py-txi; extra == 'py-txi'
	pytest; extra == 'testing'
	rich
	ruff; extra == 'quality'
	sentence-transformers; extra == 'sentence-transformers'
	timm; extra == 'timm'
	torch-ort; extra == 'torch-ort'
	torchao; extra == 'torchao'
	transformers
	typing-extensions
	vllm; extra == 'vllm'
"
GENERATED_RDEPEND="${RDEPEND}
	dev-python/accelerate[${PYTHON_USEDEP}]
	auto-gptq? ( dev-python/auto-gptq[${PYTHON_USEDEP}] )
	autoawq? ( dev-python/autoawq[${PYTHON_USEDEP}] )
	bitsandbytes? ( dev-python/bitsandbytes[${PYTHON_USEDEP}] )
	codecarbon? ( dev-python/codecarbon[${PYTHON_USEDEP}] )
	dev-python/colorlog[${PYTHON_USEDEP}]
	dev-python/datasets[${PYTHON_USEDEP}]
	deepspeed? ( dev-python/deepspeed[${PYTHON_USEDEP}] )
	diffusers? ( dev-python/diffusers[${PYTHON_USEDEP}] )
	flash-attn? ( dev-python/flash-attn[${PYTHON_USEDEP}] )
	dev-python/flatten-dict[${PYTHON_USEDEP}]
	dev-python/hydra-core[${PYTHON_USEDEP}]
	llama-cpp? ( dev-python/llama-cpp-python[${PYTHON_USEDEP}] )
	llm-swarm? ( dev-python/llm-swarm[${PYTHON_USEDEP}] )
	dev-python/nvidia-ml-py[${PYTHON_USEDEP}]
	dev-python/omegaconf[${PYTHON_USEDEP}]
	torch-ort? ( dev-python/onnxruntime-training[${PYTHON_USEDEP}] )
	auto-gptq? ( dev-python/optimum[${PYTHON_USEDEP}] )
	ipex? ( >=dev-python/optimum-1.18.0[ipex,${PYTHON_USEDEP}] )
	onnxruntime-gpu? ( >=dev-python/optimum-1.18.0[onnxruntime-gpu,${PYTHON_USEDEP}] )
	onnxruntime? ( >=dev-python/optimum-1.18.0[onnxruntime,${PYTHON_USEDEP}] )
	openvino? ( >=dev-python/optimum-1.18.0[nncf,openvino,${PYTHON_USEDEP}] )
	tensorrt-llm? ( >=dev-python/optimum-1.18.0[nvidia,${PYTHON_USEDEP}] )
	torch-ort? ( >=dev-python/optimum-1.18.0[${PYTHON_USEDEP}] )
	dev-python/pandas[${PYTHON_USEDEP}]
	peft? ( dev-python/peft[${PYTHON_USEDEP}] )
	dev-python/psutil[${PYTHON_USEDEP}]
	py-txi? ( dev-python/py-txi[${PYTHON_USEDEP}] )
	dev-python/rich[${PYTHON_USEDEP}]
	quality? ( dev-python/ruff[${PYTHON_USEDEP}] )
	sentence-transformers? ( dev-python/sentence-transformers[${PYTHON_USEDEP}] )
	timm? ( dev-python/timm[${PYTHON_USEDEP}] )
	torch-ort? ( dev-python/torch-ort[${PYTHON_USEDEP}] )
	torchao? ( dev-python/torchao[${PYTHON_USEDEP}] )
	dev-python/transformers[${PYTHON_USEDEP}]
	dev-python/typing-extensions[${PYTHON_USEDEP}]
	vllm? ( dev-python/vllm[${PYTHON_USEDEP}] )
"
RDEPEND="${GENERATED_RDEPEND}"

distutils_enable_tests pytest
GENERATED_BDEPEND="${BDEPEND}
	test? (
		dev-python/hydra-joblib-launcher[${PYTHON_USEDEP}]
		dev-python/pytest[${PYTHON_USEDEP}]
	)
"
BDEPEND="${GENERATED_BDEPEND}"

