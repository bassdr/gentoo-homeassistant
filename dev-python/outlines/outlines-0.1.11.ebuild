# This ebuild was auto-generated by homeassistant script, and the script was not able to find a better candidate.
EAPI=8

DISTUTILS_USE_PEP517=setuptools
PYTHON_COMPAT=( python3_{12,13{,t}} )
GENERATED_IUSE="exllamav2 llamacpp mlxlm openai serve test transformers vllm"
IUSE="${GENERATED_IUSE}"

inherit distutils-r1 pypi

DESCRIPTION=""
HOMEPAGE="
  https://pypi.org/project/outlines/"

LICENSE="Apache-2.0"
SLOT="0"
KEYWORDS="amd64 arm64"

REQUIRES_DIST="
	accelerate; extra == 'test'
	accelerate; extra == 'transformers'
	airportsdata
	beartype<0.16.0; extra == 'test'
	cloudpickle
	coverage[toml]>=5.1; extra == 'test'
	datasets; extra == 'llamacpp'
	datasets; extra == 'mlxlm'
	datasets; extra == 'test'
	datasets; extra == 'transformers'
	diff-cover; extra == 'test'
	diskcache
	exllamav2; extra == 'exllamav2'
	exllamav2; extra == 'test'
	fastapi; extra == 'serve'
	huggingface_hub; extra == 'test'
	interegular
	jax; extra == 'test'
	jinja2
	jsonschema
	lark
	llama-cpp-python; extra == 'llamacpp'
	llama-cpp-python; extra == 'test'
	mlx-lm; extra == 'mlxlm'
	mlx-lm>=0.19.2; (platform_machine == 'arm64' and sys_platform == 'darwin') and extra == 'test'
	nest_asyncio
	numpy
	numpy<2; extra == 'llamacpp'
	numpy<2; extra == 'transformers'
	numpy<2; extra == 'vllm'
	openai; extra == 'openai'
	openai>=1.0.0; extra == 'test'
	outlines_core==0.1.26
	pillow; extra == 'test'
	pre-commit; extra == 'test'
	pycountry
	pydantic>=2.0
	pydantic>=2.0; extra == 'serve'
	pytest-benchmark; extra == 'test'
	pytest-cov; extra == 'test'
	pytest-mock; extra == 'test'
	pytest; extra == 'test'
	referencing
	requests
	responses; extra == 'test'
	torch
	tqdm
	transformers; extra == 'llamacpp'
	transformers; extra == 'test'
	transformers; extra == 'transformers'
	transformers; extra == 'vllm'
	typing_extensions
	uvicorn; extra == 'serve'
	vllm; extra == 'vllm'
	vllm; sys_platform != 'darwin' and extra == 'test'
	vllm>=0.3.0; extra == 'serve'
"
GENERATED_RDEPEND="${RDEPEND}
	transformers? ( dev-python/accelerate[${PYTHON_USEDEP}] )
	dev-python/airportsdata[${PYTHON_USEDEP}]
	dev-python/cloudpickle[${PYTHON_USEDEP}]
	llamacpp? ( dev-python/datasets[${PYTHON_USEDEP}] )
	mlxlm? ( dev-python/datasets[${PYTHON_USEDEP}] )
	transformers? ( dev-python/datasets[${PYTHON_USEDEP}] )
	dev-python/diskcache[${PYTHON_USEDEP}]
	exllamav2? ( dev-python/exllamav2[${PYTHON_USEDEP}] )
	serve? ( dev-python/fastapi[${PYTHON_USEDEP}] )
	dev-python/interegular[${PYTHON_USEDEP}]
	dev-python/jinja2[${PYTHON_USEDEP}]
	dev-python/jsonschema[${PYTHON_USEDEP}]
	dev-python/lark[${PYTHON_USEDEP}]
	llamacpp? ( dev-python/llama-cpp-python[${PYTHON_USEDEP}] )
	mlxlm? ( dev-python/mlx-lm[${PYTHON_USEDEP}] )
	dev-python/nest-asyncio[${PYTHON_USEDEP}]
	dev-python/numpy[${PYTHON_USEDEP}]
	llamacpp? ( <dev-python/numpy-2[${PYTHON_USEDEP}] )
	transformers? ( <dev-python/numpy-2[${PYTHON_USEDEP}] )
	vllm? ( <dev-python/numpy-2[${PYTHON_USEDEP}] )
	openai? ( dev-python/openai[${PYTHON_USEDEP}] )
	~dev-python/outlines-core-0.1.26[${PYTHON_USEDEP}]
	dev-python/pycountry[${PYTHON_USEDEP}]
	>=dev-python/pydantic-2.0[${PYTHON_USEDEP}]
	serve? ( >=dev-python/pydantic-2.0[${PYTHON_USEDEP}] )
	dev-python/referencing[${PYTHON_USEDEP}]
	dev-python/requests[${PYTHON_USEDEP}]
	dev-python/torch[${PYTHON_USEDEP}]
	dev-python/tqdm[${PYTHON_USEDEP}]
	llamacpp? ( dev-python/transformers[${PYTHON_USEDEP}] )
	transformers? ( dev-python/transformers[${PYTHON_USEDEP}] )
	vllm? ( dev-python/transformers[${PYTHON_USEDEP}] )
	dev-python/typing-extensions[${PYTHON_USEDEP}]
	serve? ( dev-python/uvicorn[${PYTHON_USEDEP}] )
	serve? ( >=dev-python/vllm-0.3.0[${PYTHON_USEDEP}] )
	vllm? ( dev-python/vllm[${PYTHON_USEDEP}] )
"
RDEPEND="${GENERATED_RDEPEND}"

distutils_enable_tests pytest
GENERATED_BDEPEND="${BDEPEND}
	test? (
		dev-python/accelerate[${PYTHON_USEDEP}]
		<dev-python/beartype-0.16.0[${PYTHON_USEDEP}]
		>=dev-python/coverage-5.1[toml,${PYTHON_USEDEP}]
		dev-python/datasets[${PYTHON_USEDEP}]
		dev-python/diff-cover[${PYTHON_USEDEP}]
		dev-python/exllamav2[${PYTHON_USEDEP}]
		dev-python/huggingface-hub[${PYTHON_USEDEP}]
		dev-python/jax[${PYTHON_USEDEP}]
		dev-python/llama-cpp-python[${PYTHON_USEDEP}]
		>=dev-python/openai-1.0.0[${PYTHON_USEDEP}]
		dev-python/pillow[${PYTHON_USEDEP}]
		dev-python/pytest[${PYTHON_USEDEP}]
		dev-python/pytest-benchmark[${PYTHON_USEDEP}]
		dev-python/pytest-cov[${PYTHON_USEDEP}]
		dev-python/pytest-mock[${PYTHON_USEDEP}]
		dev-python/responses[${PYTHON_USEDEP}]
		dev-python/transformers[${PYTHON_USEDEP}]
		dev-python/vllm[${PYTHON_USEDEP}]
		dev-vcs/pre-commit[${PYTHON_USEDEP}]
	)
"
BDEPEND="${GENERATED_BDEPEND}"

